# ---------------------------------------------------------------------------------------------------------
# Copyright (c) 2025 Huawei Technologies Co., Ltd.
# This program is free software, you can redistribute it and/or modify it under the terms and conditions of 
# CANN Open Software License Agreement Version 2.0 (the "License").
# Please refer to the License for details. You may not use this file except in compliance with the License.
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED, 
# INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. 
# See LICENSE in the root of the software repository for the full text of the License.
# ---------------------------------------------------------------------------------------------------------

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys
import logging
import tensorflow as tf
import numpy as np
from tensorflow.python.framework import constant_op, dtypes

tf.compat.v1.disable_eager_execution()

# prama1: file_name: the file which store the data
# param2: data: data which will be stored
# param3: fmt: format
def write_file_txt(file_name, data, fmt="%s"):
    if (file_name is None):
        print("file name is none, do not write data to file")
        return
    dir_name = os.path.dirname(file_name)
    if not os.path.exists(dir_name):
        os.makedirs(dir_name)
    np.savetxt(file_name, data.flatten(), fmt=fmt, delimiter='', newline='\n')


# prama1: file_name: the file which store the data
# param2: dtype: data type
# param3: delim: delimiter which is used to split data
def read_file_txt(file_name, dtype, delim=None):
    return np.loadtxt(file_name, dtype=dtype, delimiter=delim).flatten()


# prama1: file_name: the file which store the data
# param2: delim: delimiter which is used to split data
def read_file_txt_to_bool(file_name, delim=None):
    in_data = np.loadtxt(file_name, dtype=str, delimiter=delim)
    bool_data = []
    for item in in_data:
        if item == "False":
            bool_data.append(False)
        else:
            bool_data.append(True)
    return np.array(bool_data)


# prama1: data_file: the file which store the generation data
# param2: shape: data shape
# param3: dtype: data type
# param4: rand_type: the method of generate data, select from "randint, uniform"
# param5: data lower limit
# param6: data upper limit
def gen_data_file(data_file, shape, dtype, rand_type, low, high):
    if rand_type == "randint":
        rand_data = np.random.randint(low, high, size=shape)
    else:
        rand_data = np.random.uniform(low, high, size=shape)
    data = np.array(rand_data, dtype=dtype)
    write_file_txt(data_file, data, fmt="%s")
    return data


def config(execute_type):
    if execute_type == 'cpu':
        session_config = tf.compat.v1.ConfigProto(
            allow_soft_placement=True,
            log_device_placement=False
        )
    return session_config


def gen_random_data_float_1d():
    data_files = ["invgrad/data/invgrad_data_input1_1.txt", 
                "invgrad/data/invgrad_data_input2_1.txt", 
                "invgrad/data/invgrad_data_output1_1.txt"]
    np.random.seed(23457)
    shape_x1 = [15]
    shape_x2 = [15]
    a = gen_data_file(data_files[0], shape_x1, np.float32, "uniform", 0, 100)
    b = gen_data_file(data_files[1], shape_x2, np.float32, "uniform", 0, 100)

    x1 = tf.compat.v1.placeholder(tf.float32, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.float32, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")


def gen_random_data_float16_1d():
    data_files = ["invgrad/data/invgrad_data_input1_2.txt", 
                "invgrad/data/invgrad_data_input2_2.txt", 
                "invgrad/data/invgrad_data_output1_2.txt"]
    np.random.seed(23457)
    shape_x1 = [16, 12]
    shape_x2 = [16, 12]
    a = gen_data_file(data_files[0], shape_x1, np.float16, "uniform", -10, 10)
    b = gen_data_file(data_files[1], shape_x2, np.float16, "uniform", -10, 10)

    x1 = tf.compat.v1.placeholder(tf.float16, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.float16, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")


def gen_random_data_double():
    data_files = ["invgrad/data/invgrad_data_input1_3.txt", 
                "invgrad/data/invgrad_data_input2_3.txt", 
                "invgrad/data/invgrad_data_output1_3.txt"]
    np.random.seed(23457)
    shape_x1 = [1, 128]
    shape_x2 = [1, 128]
    a = gen_data_file(data_files[0], shape_x1, np.float64, "uniform", -100, 100)
    b = gen_data_file(data_files[1], shape_x2, np.float64, "uniform", -100, 100)

    x1 = tf.compat.v1.placeholder(tf.float64, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.float64, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")
    

def gen_random_data_complex64():
    data_files = ["invgrad/data/invgrad_data_input1_4.txt", 
                "invgrad/data/invgrad_data_input2_4.txt", 
                "invgrad/data/invgrad_data_output1_4.txt"]
    np.random.seed(3457)
    shape_x1 = [10, 5, 5]
    shape_x2 = [10, 5, 5]
    a = gen_data_file(data_files[0], shape_x1, np.complex64, "complex", 0, 1000)
    b = gen_data_file(data_files[1], shape_x2, np.complex64, "complex", 0, 1000)

    x1 = tf.compat.v1.placeholder(tf.complex64, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.complex64, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")
  

def gen_random_data_complex128():
    data_files = ["invgrad/data/invgrad_data_input1_5.txt", 
                "invgrad/data/invgrad_data_input2_5.txt", 
                "invgrad/data/invgrad_data_output1_5.txt"]
    np.random.seed(677)
    shape_x1 = [6, 6, 6]
    shape_x2 = [6, 6, 6]
    a = gen_data_file(data_files[0], shape_x1, np.complex128, "complex", 0, 1000)
    b = gen_data_file(data_files[1], shape_x2, np.complex128, "complex", 0, 1000)
    
    x1 = tf.compat.v1.placeholder(tf.complex128, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.complex128, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")


def gen_random_data_float16_add1():
    data_files = ["invgrad/data/invgrad_data_input1_6.txt", 
                "invgrad/data/invgrad_data_input2_6.txt", 
                "invgrad/data/invgrad_data_output1_6.txt"]
    np.random.seed(23457)
    shape_x1 = [2, 1024]
    shape_x2 = [2, 1024]
    a = gen_data_file(data_files[0], shape_x1, np.float16, "uniform", -10, 10)
    b = gen_data_file(data_files[1], shape_x2, np.float16, "uniform", -10, 10)

    x1 = tf.compat.v1.placeholder(tf.float16, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.float16, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")


def gen_random_data_float16_add2():
    data_files = ["invgrad/data/invgrad_data_input1_7.txt", 
                "invgrad/data/invgrad_data_input2_7.txt", 
                "invgrad/data/invgrad_data_output1_7.txt"]
    np.random.seed(23457)
    shape_x1 = [1, 1024]
    shape_x2 = [1, 1024]
    a = gen_data_file(data_files[0], shape_x1, np.float16, "uniform", -10, 10)
    b = gen_data_file(data_files[1], shape_x2, np.float16, "uniform", -10, 10)

    x1 = tf.compat.v1.placeholder(tf.float16, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.float16, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")


def gen_random_data_float16_add3():
    data_files = ["invgrad/data/invgrad_data_input1_8.txt", 
                "invgrad/data/invgrad_data_input2_8.txt", 
                "invgrad/data/invgrad_data_output1_8.txt"]
    np.random.seed(23457)
    shape_x1 = [8192, 1]
    shape_x2 = [8192, 1]
    a = gen_data_file(data_files[0], shape_x1, np.float16, "uniform", -10, 10)
    b = gen_data_file(data_files[1], shape_x2, np.float16, "uniform", -10, 10)

    x1 = tf.compat.v1.placeholder(tf.float16, shape=shape_x1)
    x2 = tf.compat.v1.placeholder(tf.float16, shape=shape_x2)
    re = tf.raw_ops.InvGrad(y=x1, dy=x2, name="re")
    with tf.compat.v1.Session(config=config('cpu')) as session:
        data = session.run(re, feed_dict={x1: a, x2: b})
    write_file_txt(data_files[2], data, fmt="%s")


def run():

    gen_random_data_float_1d()
    gen_random_data_float16_1d()
    gen_random_data_double()
    gen_random_data_complex64()
    gen_random_data_complex128()
    gen_random_data_float16_add1()
    gen_random_data_float16_add2()
    gen_random_data_float16_add3()

if __name__ == '__main__':
    run()
