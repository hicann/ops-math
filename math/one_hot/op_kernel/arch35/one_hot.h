/**
 * Copyright (c) 2025 Huawei Technologies Co., Ltd.
 * This program is free software, you can redistribute it and/or modify it under the terms and conditions of
 * CANN Open Software License Agreement Version 2.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

/* !
 * \file one_hot.h
 * \brief
 */

#ifndef ONE_HOT_IMPL_H
#define ONE_HOT_IMPL_H

#include "kernel_operator.h"
#include "kernel_tiling/kernel_tiling.h"

using namespace AscendC;

#ifndef INFINITY
#define INFINITY (__builtin_inff())
#endif

#ifdef __DAV_FPGA__
#define BOUND_THREAD_NUM (512)
#else
#define BOUND_THREAD_NUM (1024)
#endif

namespace OneHot {
template <typename T1, typename T2, typename T3>
class OneHot {
public:
    __aicore__ inline OneHot(){};

    __aicore__ inline void Init(
        GM_ADDR x, GM_ADDR depth, GM_ADDR on_value, GM_ADDR off_value, GM_ADDR y, GM_ADDR workspace,
        const OneHotTilingData* tilingData);
    __aicore__ inline void Process();

private:
    const OneHotTilingData* tiling;
#ifdef __DAV_FPGA__
    const int32_t THREAD_NUM = 128;
#else
    const int32_t THREAD_NUM = 1024;
#endif
    const int32_t BLOCK_SIZE = 32;
    const int32_t BIT32 = 32;
    const int32_t BIT64 = 64;
    const int32_t UB_DIVISION_COUNT = 2;
    const int32_t BIT64_SIZE = 8;
    const uint64_t ONE = 1;
    const int32_t MIN_FACTOR = 1024;
    int32_t usedCoreNum_;
    uint64_t blockFactor_;
    uint64_t factor1;
    uint64_t factor2;
    int64_t depth_;
    int64_t totalInputDim_;
    T3 onValue_;
    T3 offValue_;
    int64_t blockIdx_;
    uint64_t factorOut1;
    uint64_t factorOut2;
    GlobalTensor<T1> inputGm;
    GlobalTensor<T2> depthGm;
    GlobalTensor<T3> outputGm;
    GlobalTensor<T3> onValueGm;
    GlobalTensor<T3> offValueGm;
    uint32_t shift_;
    uint32_t m_;
};

template <typename T1, typename T2, typename T3>
__aicore__ inline void OneHot<T1, T2, T3>::Init(
    GM_ADDR x, GM_ADDR depth, GM_ADDR on_value, GM_ADDR off_value, GM_ADDR y, GM_ADDR workspace,
    const OneHotTilingData* tilingData)
{
    tiling = tilingData;
    totalInputDim_ = tiling->prefixDim * tiling->suffixDim;
    inputGm.SetGlobalBuffer((__gm__ T1*)x, totalInputDim_);
    // output reuse input
    depthGm.SetGlobalBuffer((__gm__ T2*)depth, 1);
    depth_ = static_cast<int64_t>(depthGm.GetValue(0));
    outputGm.SetGlobalBuffer((__gm__ T3*)y, totalInputDim_ * depth_);
    onValueGm.SetGlobalBuffer((__gm__ T3*)on_value, 1);
    offValueGm.SetGlobalBuffer((__gm__ T3*)off_value, 1);
    onValue_ = static_cast<T3>(onValueGm.GetValue(0));
    offValue_ = static_cast<T3>(offValueGm.GetValue(0));
    usedCoreNum_ = tiling->usedCoreNum;
    blockFactor_ = tiling->perCoreCalSize;
    factor1 = tiling->suffixDim;
    factorOut1 = tiling->suffixDim * depth_;
    factorOut2 = tiling->suffixDim;
    // fast division
    auto lz = BIT64 - clz(factor1);
    auto bc = bcnt1(factor1);
    shift_ = (bc != 1) ? lz : lz - 1;
    uint64_t magic = ((ONE << BIT32) * ((ONE << shift_) - factor1)) / factor1 + 1;
    m_ = static_cast<uint32_t>(magic);
}

template <typename T1, typename T2, typename T3>
__simt_vf__ __aicore__ LAUNCH_BOUND(BOUND_THREAD_NUM) inline void SimtComputeFor64(
    int64_t startOffset, int64_t coreFactor, int64_t depth, T3 offValue, T3 onValue, uint64_t factor1,
    uint64_t factorOut1, uint64_t factorOut2, __gm__ T1* inputData, __gm__ T3* outputData)
{
    for (int64_t idx = static_cast<int64_t>(Simt::GetThreadIdx()); idx < coreFactor;
         idx += static_cast<int64_t>(Simt::GetThreadNum())) {
        int64_t gmIdx = startOffset + idx;
        int64_t i = gmIdx / factor1;
        int64_t j = gmIdx % factor1;
        int64_t dstOffset;
        for (int64_t axisIdx = 0; axisIdx < depth; axisIdx++) {
            dstOffset = i * factorOut1 + axisIdx * factorOut2 + j;
            outputData[dstOffset] = offValue;
        }
        if (inputData[gmIdx] < depth && inputData[gmIdx] >= 0) {
            dstOffset = i * factorOut1 + inputData[gmIdx] * factorOut2 + j;
            outputData[dstOffset] = onValue;
        }
    }
}

template <typename T1, typename T2, typename T3>
__simt_vf__ __aicore__ LAUNCH_BOUND(BOUND_THREAD_NUM) inline void SimtCompute(
    int32_t startOffset, int32_t coreFactor, int64_t depth, T3 offValue, T3 onValue, uint64_t factor1,
    uint64_t factorOut1, uint64_t factorOut2, uint32_t m, uint32_t shift, __gm__ T1* inputData, __gm__ T3* outputData)
{
    for (uint32_t idx = static_cast<int32_t>(Simt::GetThreadIdx<1>()); idx < coreFactor;
         idx += static_cast<int32_t>(Simt::GetThreadNum<1>())) {
        int32_t gmIdx = startOffset + idx;
        uint32_t t = __umulhi(gmIdx, m);
        t = t + gmIdx;
        int32_t i = t >> shift;
        int32_t j = gmIdx - i * factor1;
        int64_t dstOffset;
        for (int64_t axisIdx = static_cast<int64_t>(Simt::GetThreadIdx<0>()); axisIdx < depth;
             axisIdx += static_cast<int64_t>(Simt::GetThreadNum<0>())) {
            dstOffset = i * factorOut1 + axisIdx * factorOut2 + j;
            outputData[dstOffset] = offValue;
        }
        if (inputData[gmIdx] < depth && inputData[gmIdx] >= 0) {
            dstOffset = i * factorOut1 + inputData[gmIdx] * factorOut2 + j;
            outputData[dstOffset] = onValue;
        }
    }
}

template <typename T1, typename T2, typename T3>
__simt_vf__ __aicore__ LAUNCH_BOUND(BOUND_THREAD_NUM) inline void SimtComputeDepth(
    int32_t startOffset, int32_t coreFactor, int64_t depth, T3 offValue, T3 onValue, uint64_t factor1,
    uint64_t factorOut1, uint64_t factorOut2, uint32_t m, uint32_t shift, __gm__ T1* inputData, __gm__ T3* outputData)
{
    for (uint32_t idx = static_cast<int32_t>(Simt::GetThreadIdx<>()); idx < coreFactor;
         idx += static_cast<int32_t>(Simt::GetThreadNum<>())) {
        int32_t gmIdx = startOffset + idx;
        uint32_t t = __umulhi(gmIdx, m);
        t = t + gmIdx;
        int32_t i = t >> shift;
        int32_t j = gmIdx - i * factor1;
        int64_t dstOffset = i * factorOut1 + j;
        if (inputData[gmIdx] < depth && inputData[gmIdx] >= 0) {
            outputData[dstOffset] = onValue;
        } else {
            outputData[dstOffset] = offValue;
        }
    }
}

template <typename T1, typename T2, typename T3>
__aicore__ inline void OneHot<T1, T2, T3>::Process()
{
    int64_t coreFactor = blockFactor_;
    blockIdx_ = GetBlockIdx();
    if (blockIdx_ >= usedCoreNum_ || blockFactor_ == 0) {
        return;
    }
    if (tiling->hasTail && blockIdx_ > 0 && blockIdx_ == usedCoreNum_ - 1) {
        // 尾块核
        if (totalInputDim_ <= tiling->coreNum * MIN_FACTOR) {
            coreFactor = totalInputDim_ % MIN_FACTOR;
        } else {
            coreFactor = blockFactor_ + totalInputDim_ % tiling->coreNum;
        }
    }
    int64_t startOffset = blockFactor_ * blockIdx_;
    __gm__ T1* inputData = inputGm.GetPhyAddr(0);
    __gm__ T3* outputData = outputGm.GetPhyAddr(0);
    if (depth_ == 1) {
        auto threadsPerBlock = cce::dim3{static_cast<unsigned int>(THREAD_NUM)};
        Simt::VF_CALL<SimtComputeDepth<T1, T2, T3>>(
            threadsPerBlock, startOffset, coreFactor, depth_, offValue_, onValue_, factor1, factorOut1, factorOut2, m_,
            shift_, inputData, outputData);
    } else {
        int32_t dimX = THREAD_NUM / coreFactor == 0 ? 1 : THREAD_NUM / coreFactor;
        int32_t dimY = THREAD_NUM / dimX == 0 ? 1 : THREAD_NUM / dimX;
        if (dimX > dimY) {
            dimX = dimX / BLOCK_SIZE * BLOCK_SIZE == 0 ? 1 : dimX / BLOCK_SIZE * BLOCK_SIZE;
        } else {
            dimY = dimY / BLOCK_SIZE * BLOCK_SIZE == 0 ? 1 : dimY / BLOCK_SIZE * BLOCK_SIZE;
        }
        auto threadsPerBlock = cce::dim3{static_cast<unsigned int>(dimX), static_cast<unsigned int>(dimY)};
        if (unlikely(startOffset > INT32_MAX)) {
            Simt::VF_CALL<SimtComputeFor64<T1, T2, T3>>(
                threadsPerBlock, startOffset, coreFactor, depth_, offValue_, onValue_, factor1, factorOut1, factorOut2,
                inputData, outputData);
        } else {
            Simt::VF_CALL<SimtCompute<T1, T2, T3>>(
                threadsPerBlock, static_cast<int32_t>(startOffset), static_cast<int32_t>(coreFactor), depth_, offValue_,
                onValue_, factor1, factorOut1, factorOut2, m_, shift_, inputData, outputData);
        }
    }
}
} // namespace OneHot
#endif