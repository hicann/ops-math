/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2025. All rights reserved.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 2.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */
#include <array>
#include <vector>
#include "gtest/gtest.h"

#include "level2/aclnn_addr.h"

#include "op_api_ut_common/op_api_ut.h"
#include "op_api_ut_common/scalar_desc.h"
#include "op_api_ut_common/tensor_desc.h"

using namespace std;

class l2_addr_test : public testing::Test {
 protected:
  static void SetUpTestCase() {
    cout << "addr_test SetUp" << endl;
  }

  static void TearDownTestCase() {
    cout << "addr_test TearDown" << endl;
  }
};

// *** tensor dtype test ***
// test dtype: FLOAT16
TEST_F(l2_addr_test, case_addr_for_float16_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: BFLOAT16
TEST_F(l2_addr_test, ascend910B2_addr_dtype_bfloat16) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_BF16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_BF16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_BF16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);
}

// test dtype: BFLOAT16 91095
TEST_F(l2_addr_test, ascend910_95_addr_dtype_bfloat16) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_BF16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_BF16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_BF16, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);
}

// test dtype: FLOAT/FLOAT32
TEST_F(l2_addr_test, case_addr_for_float_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto beta_scalar_desc = ScalarDesc(1.5f);
  auto alpha_scalar_desc = ScalarDesc(1.1f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: DOUBLE
TEST_F(l2_addr_test, case_addr_for_double_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto beta_scalar_desc = ScalarDesc(1.5f);
  auto alpha_scalar_desc = ScalarDesc(1.1f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: INT8
TEST_F(l2_addr_test, case_addr_for_int8_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_INT8, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_INT8, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_INT8, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<int8_t>(5));
  auto alpha_scalar_desc = ScalarDesc(static_cast<int8_t>(-5));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: INT16
TEST_F(l2_addr_test, case_addr_for_int16_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_INT16, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_INT16, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_INT16, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<int16_t>(2));
  auto alpha_scalar_desc = ScalarDesc(static_cast<int16_t>(10));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: INT32
TEST_F(l2_addr_test, case_addr_for_int32_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_INT32, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_INT32, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_INT32, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<int32_t>(-10));
  auto alpha_scalar_desc = ScalarDesc(static_cast<int32_t>(2));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: INT64
TEST_F(l2_addr_test, case_addr_for_int64_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_INT64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_INT64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_INT64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<int64_t>(3));
  auto alpha_scalar_desc = ScalarDesc(static_cast<int64_t>(1));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: UINT8
TEST_F(l2_addr_test, case_addr_for_uint8_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_UINT8, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_UINT8, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_UINT8, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<uint8_t>(2));
  auto alpha_scalar_desc = ScalarDesc(static_cast<uint8_t>(2));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test dtype: BOOL
TEST_F(l2_addr_test, case_addr_for_bool_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_BOOL, ACL_FORMAT_ND).ValueRange(false, true);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_BOOL, ACL_FORMAT_ND).ValueRange(false, true);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_BOOL, ACL_FORMAT_ND).ValueRange(false, true);
  auto beta_scalar_desc = ScalarDesc(static_cast<bool>(true));
  auto alpha_scalar_desc = ScalarDesc(static_cast<bool>(true));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// test invalid input type
TEST_F(l2_addr_test, case_addr_for_invalid_complex_type) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_COMPLEX64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_COMPLEX64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_COMPLEX64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_INVALID);
}

// input tensor is not bool tensor when beta/alpha's dtype is boolean
TEST_F(l2_addr_test, case_addr_for_bool_scalar_without_bool_input) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_BOOL, ACL_FORMAT_ND).ValueRange(false, true);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_BOOL, ACL_FORMAT_ND).ValueRange(false, true);
  auto beta_scalar_desc = ScalarDesc(static_cast<bool>(true));
  auto alpha_scalar_desc = ScalarDesc(static_cast<bool>(true));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_INVALID);
}

// all input tensors have integal type, but beta/alpha has floating type
TEST_F(l2_addr_test, case_addr_for_floating_scalar_under_int_input) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_INT32, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_INT32, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_INT32, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_INVALID);
}

// *** tensor rank range ***
// vec1 is a empty tensor
TEST_F(l2_addr_test, case_addr_for_left_vec_is_empty_tensor) {
  auto self_tensor_desc = TensorDesc({1, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({0}, ACL_FLOAT, ACL_FORMAT_ND);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);
}

// vec2 is a empty tensor
TEST_F(l2_addr_test, case_addr_for_right_vec_is_empty_tensor) {
  auto self_tensor_desc = TensorDesc({4, 1}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({0}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);
}

// vec is not a 1D tensor
TEST_F(l2_addr_test, case_addr_for_vec_isnot_1d_tensor) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3, 2}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_INVALID);
}

// self dims is over 2
TEST_F(l2_addr_test, case_addr_for_self_dims_over_two) {
  auto self_tensor_desc = TensorDesc({4, 3, 2}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_INVALID);
}

// self can not broadcast to outer of vec1 and vec2
TEST_F(l2_addr_test, case_addr_for_unable_broadcast_within_self_vec12) {
  auto self_tensor_desc = TensorDesc({5, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_INVALID);
}

// *** tensor relationship constraint test ***
// vecs have different dtype, test dtype cast
TEST_F(l2_addr_test, case_addr_for_vec_dtype_cast) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_INT16, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<float>(100.200000));
  auto alpha_scalar_desc = ScalarDesc(static_cast<float>(200.500000));
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// vecs have different dtype with input, test dtype cast
TEST_F(l2_addr_test, case_addr_for_input_dtype_cast) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_INT64, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<double>(100.200000));
  auto alpha_scalar_desc = ScalarDesc(static_cast<double>(200.500000));
  auto out_tensor_desc = TensorDesc({4, 3}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-10, 10);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// out has different dtype with input, test dtype cast
TEST_F(l2_addr_test, case_addr_for_out_dtype_cast) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(static_cast<float>(100.200000));
  auto alpha_scalar_desc = ScalarDesc(static_cast<float>(200.500000));
  auto out_tensor_desc = TensorDesc({4, 3}, ACL_DOUBLE, ACL_FORMAT_ND).ValueRange(-10, 10);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// *** nullptr test ***
// test nullptr input
TEST_F(l2_addr_test, case_addr_for_nullptr_input) {
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT((aclTensor*)nullptr, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_NULLPTR);
}

// test nullptr vec
TEST_F(l2_addr_test, case_addr_for_nullptr_vec) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, (aclTensor*)nullptr, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_NULLPTR);
}

// test nullptr output
TEST_F(l2_addr_test, case_addr_for_nullptr_output) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-10, 10);
  auto beta_scalar_desc = ScalarDesc(1.0f);
  auto alpha_scalar_desc = ScalarDesc(1.0f);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, (aclTensor*)nullptr, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT((aclTensor*)nullptr));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACLNN_ERR_PARAM_NULLPTR);
}

// test nullptr scalar, handle with default value
TEST_F(l2_addr_test, case_addr_for_nullptr_scalar) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, (aclScalar*)nullptr, (aclScalar*)nullptr),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}

// *** contiguous ***
// test continuity
// test nullptr scalar, handle with default value
TEST_F(l2_addr_test, case_addr_for_continuity) {
  auto self_tensor_desc = TensorDesc({4, 3}, ACL_FLOAT, ACL_FORMAT_ND, {1, 5}, 0, {4, 5}).ValueRange(-2.0, 2.0);
  auto vec1_tensor_desc = TensorDesc({4}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto vec2_tensor_desc = TensorDesc({3}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-2.0, 2.0);
  auto beta_scalar_desc = ScalarDesc(2.0f);
  auto alpha_scalar_desc = ScalarDesc(3.0f);
  auto out_tensor_desc = TensorDesc(self_tensor_desc).Precision(0.0001, 0.0001);

  auto ut = OP_API_UT(aclnnAddr,
                      INPUT(self_tensor_desc, vec1_tensor_desc, vec2_tensor_desc, beta_scalar_desc, alpha_scalar_desc),
                      OUTPUT(out_tensor_desc));

  uint64_t workspace_size = 0;
  aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspace_size);
  EXPECT_EQ(aclRet, ACL_SUCCESS);

  ut.TestPrecision();
}