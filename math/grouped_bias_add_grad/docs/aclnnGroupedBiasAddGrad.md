# aclnnGroupedBiasAddGrad

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-math-dev/tree/master/math/grouped_bias_add_grad)

## äº§å“æ”¯æŒæƒ…å†µ

| äº§å“                                                         | æ˜¯å¦æ”¯æŒ |
| :----------------------------------------------------------- | :------: |
| <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>                             |    Ã—     |
| <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>     |    âˆš     |
| <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term> |    âˆš     |





## åŠŸèƒ½è¯´æ˜

- ç®—å­åŠŸèƒ½ï¼šåˆ†ç»„åç½®åŠ æ³•ï¼ˆGroupedBiasAddï¼‰çš„åå‘è®¡ç®—ã€‚æœ¬æ¥å£çš„æ‰©å±•æ¥å£æ˜¯[aclnnGroupedBiasAddGradV2](./aclnnGroupedBiasAddGradV2.md)ã€‚
- è®¡ç®—å…¬å¼ï¼š<br>
(1) æœ‰å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼š

$$
out(G,H) = \begin{cases} \sum_{i=groupIdxOptional(j-1)}^{groupIdxOptional(j)}  gradY(i, H), & 1 \leq j \leq G-1 \\  \sum_{i=0}^{groupIdxOptional(j)}  gradY(i, H), & j = 0 \end{cases}
$$

&emsp;&emsp;å…¶ä¸­ï¼ŒgradYå…±2ç»´ï¼ŒHè¡¨ç¤ºgradYæœ€åä¸€ç»´çš„å¤§å°ï¼ŒGè¡¨ç¤ºgroupIdxOptionalç¬¬0ç»´çš„å¤§å°ï¼Œå³groupIdxOptionalæœ‰Gä¸ªæ•°ï¼ŒgroupIdxOptional(j)è¡¨ç¤ºç¬¬jä¸ªæ•°çš„å¤§å°ï¼Œè®¡ç®—åoutä¸º2ç»´ï¼Œshapeä¸º(G, H)ã€‚<br>
&emsp;&emsp;(2) æ— å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼š

$$
out(G, H) = \sum_{i=0}^{C} gradY(G, i, H)
$$

&emsp;&emsp;å…¶ä¸­ï¼ŒgradYå…±3ç»´ï¼ŒG, C, Hä¾æ¬¡è¡¨ç¤ºgradYç¬¬0-2ç»´çš„å¤§å°ï¼Œè®¡ç®—åoutä¸º2ç»´ï¼Œshapeä¸º(G, H)ã€‚
- ç¤ºä¾‹ï¼š<br>
(1) æœ‰å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼š<br>
  gradYçš„shapeä¸º(1000, 30)ï¼ŒgroupIdxOptionalä¸º(400, 600, 1000)ï¼Œå°†gradYåˆ†ä¸º3ç»„ï¼Œæ¯ç»„ç´¯åŠ çš„è¡Œæ•°ä¾æ¬¡ä¸º400ã€200ã€400ï¼Œè®¡ç®—åoutçš„shapeä¸º(3, 30)ã€‚<br>
(2) æ— å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼š<br>
  gradYçš„shapeä¸º(10, 100, 30)ï¼Œå°†gradYåˆ†ä¸º10ç»„ï¼Œæ¯ç»„ç´¯åŠ çš„è¡Œæ•°å‡ä¸º100ï¼Œè®¡ç®—åoutçš„shapeä¸º(10, 30)ã€‚

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnGroupedBiasAddGradGetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnGroupedBiasAddGradâ€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

- `aclnnStatus aclnnGroupedBiasAddGradGetWorkspaceSize(const aclTensor *gradY, const aclTensor *groupIdxOptional, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor)`
- `aclnnStatus aclnnGroupedBiasAddGrad(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, aclrtStream stream)`

## aclnnGroupedBiasAddGradGetWorkspaceSize

- **å‚æ•°è¯´æ˜ï¼š**

  * gradYï¼ˆaclTensor\*ï¼Œè®¡ç®—è¾“å…¥ï¼‰: å¿…é€‰å‚æ•°ï¼Œåå‘ä¼ æ’­æ¢¯åº¦ï¼Œå…¬å¼ä¸­çš„gradYï¼ŒDeviceä¾§çš„aclTensorï¼Œæ•°æ®ç±»å‹æ”¯æŒFLOATã€FLOAT16ã€BFLOAT16ã€‚æœ‰å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼Œshapeä»…æ”¯æŒ2ç»´ï¼Œæ— å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼Œshapeä»…æ”¯æŒ3ç»´ï¼Œæ”¯æŒ[éè¿ç»­çš„Tensor](../../../docs/context/éè¿ç»­çš„Tensor.md)ï¼Œ[æ•°æ®æ ¼å¼](../../../docs/context/æ•°æ®æ ¼å¼.md)æ”¯æŒNDã€‚
  * groupIdxOptionalï¼ˆaclTensor\*ï¼Œè®¡ç®—è¾“å…¥ï¼‰: å¯é€‰å‚æ•°ï¼Œæ¯ä¸ªåˆ†ç»„ç»“æŸä½ç½®ï¼Œå…¬å¼ä¸­çš„groupIdxOptionalï¼ŒDeviceä¾§çš„aclTensorï¼Œæ•°æ®ç±»å‹æ”¯æŒINT32ï¼ŒINT64ï¼Œshapeä»…æ”¯æŒ1ç»´ï¼Œæ”¯æŒ[éè¿ç»­çš„Tensor](../../../docs/context/éè¿ç»­çš„Tensor.md)ï¼Œ[æ•°æ®æ ¼å¼](../../../docs/context/æ•°æ®æ ¼å¼.md)æ”¯æŒNDã€‚
  * outï¼ˆaclTensor\*ï¼Œè®¡ç®—è¾“å‡ºï¼‰: biasçš„æ¢¯åº¦ï¼Œå…¬å¼ä¸­çš„outï¼ŒDeviceä¾§çš„aclTensorï¼Œæ•°æ®ç±»å‹æ”¯æŒFLOATã€FLOAT16ã€BFLOAT16ï¼Œæ•°æ®ç±»å‹å¿…é¡»ä¸gradYçš„æ•°æ®ç±»å‹ä¸€è‡´ï¼Œshapeä»…æ”¯æŒ2ç»´ï¼Œæ”¯æŒ[éè¿ç»­çš„Tensor](../../../docs/context/éè¿ç»­çš„Tensor.md)ï¼Œ[æ•°æ®æ ¼å¼](../../../docs/context/æ•°æ®æ ¼å¼.md)æ”¯æŒNDã€‚
  * workspaceSizeï¼ˆuint64\_t\*ï¼Œå‡ºå‚ï¼‰: è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚
  * executorï¼ˆaclOpExecutor\*\*ï¼Œå‡ºå‚ï¼‰: è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚

- **è¿”å›å€¼ï¼š**

  aclnnStatus: è¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/context/aclnnè¿”å›ç .md)ã€‚
  ```
  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š
  161001(ACLNN_ERR_PARAM_NULLPTR)ï¼šä¼ å…¥çš„gradYã€outæ˜¯ç©ºæŒ‡é’ˆæ—¶ã€‚
  161002(ACLNN_ERR_PARAM_INVALID): 1. gradYæˆ–outçš„æ•°æ®ç±»å‹/ç»´åº¦ä¸åœ¨æ”¯æŒçš„èŒƒå›´å†…ã€‚
                                   2. gradYã€groupIdxOptionalã€outçš„ç»´åº¦å…³ç³»ä¸åŒ¹é…ã€‚
                                   3. groupç»„æ•°è¶…è¿‡2048ã€‚
  ```

## aclnnGroupedBiasAddGrad

- **å‚æ•°è¯´æ˜ï¼š**

  * workspaceï¼ˆvoid\*ï¼Œå…¥å‚ï¼‰: åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚
  * workspaceSizeï¼ˆuint64\_tï¼Œå…¥å‚ï¼‰: åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnGroupedBiasAddGradGetWorkspaceSizeè·å–ã€‚
  * executorï¼ˆaclOpExecutor\*ï¼Œå…¥å‚ï¼‰: opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚
  * streamï¼ˆaclrtStreamï¼Œå…¥å‚ï¼‰: æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚

- **è¿”å›å€¼ï¼š**

  aclnnStatus: è¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜

- ç¡®å®šæ€§è®¡ç®—ï¼š
  - aclnnGroupedBiasAddGradé»˜è®¤ç¡®å®šæ€§å®ç°ã€‚
- groupIdxOptionalæœ€å¤§æ”¯æŒ2048ä¸ªæ•°ã€‚
- æœ‰å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼Œéœ€è¦ä¿è¯Tensoræ•°æ®æ˜¯é€’å¢æ’åˆ—ï¼Œä¸”æœ€åä¸€ä¸ªæ•°å€¼éœ€è¦ç­‰äºgradYç¬¬0ç»´çš„å¤§å°ã€‚
- æœ‰å¯é€‰è¾“å…¥groupIdxOptionalæ—¶ï¼Œéœ€è¦ä¿è¯Tensoræ•°å€¼ä¸è¶…è¿‡INT32æœ€å¤§å€¼ï¼Œå¹¶ä¸”æ˜¯éè´Ÿæ•°ã€‚

## è°ƒç”¨ç¤ºä¾‹

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

```Cpp
#include <iostream>
#include <vector>
#include "acl/acl.h"
#include "aclnnop/aclnn_grouped_bias_add_grad.h"

#define CHECK_RET(cond, return_expr) \
  do {                               \
    if (!(cond)) {                   \
      return_expr;                   \
    }                                \
  } while (0)

#define LOG_PRINT(message, ...)     \
  do {                              \
    printf(message, ##__VA_ARGS__); \
  } while (0)

int64_t GetShapeSize(const std::vector<int64_t>& shape) {
  int64_t shape_size = 1;
  for (auto i : shape) {
    shape_size *= i;
  }
  return shape_size;
}

int Init(int32_t deviceId, aclrtStream* stream) {
  // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
  auto ret = aclInit(nullptr);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
  ret = aclrtSetDevice(deviceId);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
  ret = aclrtCreateStream(stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
  return 0;
}

template <typename T>
int CreateAclTensor(const std::vector<T>& hostData, const std::vector<int64_t>& shape, void** deviceAddr,
                    aclDataType dataType, aclTensor** tensor) {
  auto size = GetShapeSize(shape) * sizeof(T);
  // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
  auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);

  // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
  ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

  // è®¡ç®—è¿ç»­tensorçš„strides
  std::vector<int64_t> strides(shape.size(), 1);
  for (int64_t i = shape.size() - 2; i >= 0; i--) {
    strides[i] = shape[i + 1] * strides[i + 1];
  }

  // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
  *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                            shape.data(), shape.size(), *deviceAddr);
  return 0;
}

int main() {
  // 1. ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–, å‚è€ƒacl APIæ‰‹å†Œ
  // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
  int32_t deviceId = 0;
  aclrtStream stream;
  auto ret = Init(deviceId, &stream);
  // checkæ ¹æ®è‡ªå·±çš„éœ€è¦å¤„ç†
  CHECK_RET(ret == 0, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);
  // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
  std::vector<int64_t> gradYShape = {40, 10};
  std::vector<int64_t> groupIdxShape = {4};
  std::vector<int64_t> outShape = {4, 10};
  void* gradYDeviceAddr = nullptr;
  void* groupIdxDeviceAddr = nullptr;
  void* outDeviceAddr = nullptr;
  aclTensor* gradY = nullptr;
  aclTensor* groupIdx = nullptr;
  aclTensor* out = nullptr;

  std::vector<float> gradYHostData(400, 1.0);

  std::vector<int32_t> groupIdxHostData = {5, 15, 30, 40};
  std::vector<float> outHostData(40, 0.0);

  // åˆ›å»ºgradY aclTensor
  ret = CreateAclTensor(gradYHostData, gradYShape, &gradYDeviceAddr, aclDataType::ACL_FLOAT, &gradY);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  // åˆ›å»ºgroupIdxOptional aclTensor
  ret = CreateAclTensor(groupIdxHostData, groupIdxShape, &groupIdxDeviceAddr, aclDataType::ACL_INT32, &groupIdx);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  // åˆ›å»ºout aclTensor
  ret = CreateAclTensor(outHostData, outShape, &outDeviceAddr, aclDataType::ACL_FLOAT, &out);
  CHECK_RET(ret == ACL_SUCCESS, return ret);

  // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„API
  uint64_t workspaceSize = 0;
  aclOpExecutor* executor;
  // è°ƒç”¨aclnnGroupedBiasAddGradç¬¬ä¸€æ®µæ¥å£
  ret = aclnnGroupedBiasAddGradGetWorkspaceSize(gradY, groupIdx, out, &workspaceSize, &executor);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnGroupedBiasAddGradGetWorkspaceSize failed. ERROR: %d\n", ret); return ret);
  // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
  void* workspaceAddr = nullptr;
  if (workspaceSize > 0) {
    ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret;);
  }
  // è°ƒç”¨aclnnGroupedBiasAddGradç¬¬äºŒæ®µæ¥å£
  ret = aclnnGroupedBiasAddGrad(workspaceAddr, workspaceSize, executor, stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnGroupedBiasAddGrad failed. ERROR: %d\n", ret); return ret);
  // 4. ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
  ret = aclrtSynchronizeStream(stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);
  // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
  auto size = GetShapeSize(outShape);
  std::vector<float> resultData(size, 0);
  ret = aclrtMemcpy(resultData.data(), resultData.size() * sizeof(resultData[0]), outDeviceAddr, size * sizeof(float),
                    ACL_MEMCPY_DEVICE_TO_HOST);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret); return ret);
  for (int64_t i = 0; i < size; i++) {
    LOG_PRINT("result[%ld] is: %f\n", i, resultData[i]);
  }

  // 6. é‡Šæ”¾aclTensorï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
  aclDestroyTensor(gradY);
  aclDestroyTensor(groupIdx);
  aclDestroyTensor(out);

  // 7. é‡Šæ”¾deviceèµ„æºï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
  aclrtFree(groupIdxDeviceAddr);
  aclrtFree(outDeviceAddr);
  aclrtFree(gradYDeviceAddr);
  if (workspaceSize > 0) {
    aclrtFree(workspaceAddr);
  }
  aclrtDestroyStream(stream);
  aclrtResetDevice(deviceId);
  aclFinalize();
  return 0;
}
```
